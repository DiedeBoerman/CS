{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Science Assignment\n",
    "**Course**: Computer Science <br>\n",
    "**Title**: Scalable Product Duplicate Detection <br>\n",
    "**Author**: Diede Boerman (617807) <br>\n",
    "**Teacher**: dr. Flavius Frasincar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to create a scalable solution for duplicate product detection. We propose a solution that reduces the required number of computations by lowering the number of comparisons. We aim to achieve this by presenting a Locality Sensitive Hashing technique (LSH). <br>\n",
    "In this document we provide the code used for programming the methods needed to obtain a suitable solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "from random import randint, random, sample\n",
    "import re\n",
    "import itertools\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the provided datafile \n",
    "TVset = open('TVs-all-merged.json')\n",
    " \n",
    "# Return json file as dictionary\n",
    "data = json.load(TVset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'workable' list of json file\n",
    "ModelID = list(data.keys())\n",
    "\n",
    "N = len(ModelID) #length is 1262 and hence including duplicates\n",
    "i = 0\n",
    "dataframe = []\n",
    "\n",
    "while i < N:\n",
    "    if len(data[ModelID[i]]) == 1: \n",
    "        dataframe.append(data[ModelID[i]][0])\n",
    "    else:\n",
    "        for duplicate in data[ModelID[i]]: \n",
    "            dataframe.append(duplicate)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we extract so-called 'model words' from the titles of the products. We initialize an empty set to store all model words retrieved from the titles. This set is used later on to create a binary vector representation for each product. Also, we do some data cleaning to remove frequently observed inconsistencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model words from product titles. \n",
    "i = 0 \n",
    "MW = [] #initialize empty list for collecting model words.\n",
    "Title_list = [] #initialize empty list for collecting titles. \n",
    "\n",
    "# Extract model words from titles of all 1624 products \n",
    "while i < N:\n",
    "    if len(data[ModelID[i]]) == 1: \n",
    "        MW.extend(data[ModelID[i]][0]['title'].split()) \n",
    "    else:\n",
    "        for duplicate in data[ModelID[i]]: \n",
    "            MW.extend(duplicate['title'].split())\n",
    "    i+=1\n",
    "\n",
    "# Data cleaning model words\n",
    "MW = [w.lower() for w in MW]\n",
    "MW = [w.replace('\"', '-inch') for w in MW]\n",
    "MW = [w.replace('-lcd', 'lcd') for w in MW]\n",
    "MW = [w.replace('-hz', 'hz') for w in MW]\n",
    "for char in string.punctuation: \n",
    "    MW = [w.strip(char) for w in MW]\n",
    "\n",
    "# Extracting titles and clean them\n",
    "i=0\n",
    "\n",
    "while i<N:\n",
    "    if len(data[ModelID[i]])==1:\n",
    "        prod_title = data[ModelID[i]][0]['title'].lower()\n",
    "        prod_title = prod_title.replace('\"','-inch')\n",
    "        prod_title = prod_title.replace('-lcd', 'lcd')\n",
    "        prod_title = prod_title.replace('-hz','hz')\n",
    "        Title_list.append(prod_title)\n",
    "    else:\n",
    "        for duplicate in data[ModelID[i]]:\n",
    "            prod_title = duplicate['title'].lower()\n",
    "            prod_title = prod_title.replace('\"', '-inch')\n",
    "            prod_title = prod_title.replace('-lcd', 'lcd')\n",
    "            prod_title = prod_title.replace('-hz','hz')\n",
    "            Title_list.append(prod_title)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the set of model words (*MW*), we create a binary vector representation for each product. If the title of a product contains a specific model word from *MW*, the elemnt in the binary vector corresponding to this word is set to 1 (and 0 otherwise). The results are stored in a matrix containing representations for all products. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hdtv</th>\n",
       "      <th>1080p</th>\n",
       "      <th>class</th>\n",
       "      <th>led</th>\n",
       "      <th>diag</th>\n",
       "      <th>newegg.com</th>\n",
       "      <th>best</th>\n",
       "      <th>buy</th>\n",
       "      <th>3d</th>\n",
       "      <th>samsung</th>\n",
       "      <th>...</th>\n",
       "      <th>42ln5200</th>\n",
       "      <th>th-37lru5</th>\n",
       "      <th>22lv255c</th>\n",
       "      <th>45.9-inchdiagonal</th>\n",
       "      <th>un46f5000afxza</th>\n",
       "      <th>60125-inch</th>\n",
       "      <th>45.9</th>\n",
       "      <th>nt-1907</th>\n",
       "      <th>un46es7100fxza</th>\n",
       "      <th>e424</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1624 rows × 1638 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hdtv 1080p class led diag newegg.com best buy 3d samsung  ... 42ln5200  \\\n",
       "0       1     0     1   1    1          0    1   1  0       0  ...        0   \n",
       "1       1     0     0   1    0          1    0   0  0       0  ...        0   \n",
       "2       1     1     1   1    1          0    1   1  1       0  ...        0   \n",
       "3       1     1     1   1    1          0    1   1  0       0  ...        0   \n",
       "4       1     1     1   1    1          1    0   0  0       0  ...        0   \n",
       "...   ...   ...   ...  ..  ...        ...  ...  .. ..     ...  ...      ...   \n",
       "1619    1     1     1   0    0          0    0   0  1       0  ...        0   \n",
       "1620    1     1     1   1    1          0    1   1  0       1  ...        0   \n",
       "1621    1     1     1   1    1          1    0   0  0       1  ...        0   \n",
       "1622    1     1     1   1    0          0    0   0  0       0  ...        0   \n",
       "1623    1     1     1   1    1          0    1   1  0       0  ...        0   \n",
       "\n",
       "     th-37lru5 22lv255c 45.9-inchdiagonal un46f5000afxza 60125-inch 45.9  \\\n",
       "0            0        0                 0              0          0    0   \n",
       "1            0        0                 0              0          0    0   \n",
       "2            0        0                 0              0          0    0   \n",
       "3            0        0                 0              0          0    0   \n",
       "4            0        0                 0              0          0    0   \n",
       "...        ...      ...               ...            ...        ...  ...   \n",
       "1619         0        0                 0              0          0    0   \n",
       "1620         0        0                 0              0          0    0   \n",
       "1621         0        0                 0              0          0    0   \n",
       "1622         0        0                 0              0          0    0   \n",
       "1623         0        0                 0              0          0    0   \n",
       "\n",
       "     nt-1907 un46es7100fxza e424  \n",
       "0          0              0    0  \n",
       "1          0              0    0  \n",
       "2          0              0    0  \n",
       "3          0              0    0  \n",
       "4          0              0    0  \n",
       "...      ...            ...  ...  \n",
       "1619       0              0    0  \n",
       "1620       0              0    0  \n",
       "1621       0              0    0  \n",
       "1622       0              0    0  \n",
       "1623       0              0    1  \n",
       "\n",
       "[1624 rows x 1638 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set columns for dataframe in kind of a cumbersome way...\n",
    "words = Counter(MW) #keeps track of how many words are in the list\n",
    "words = words.most_common() #keeps track of how many times equivalent words are added\n",
    "\n",
    "binrep_words = []\n",
    "\n",
    "for tup in words:\n",
    "    if tup[1] >= 1: #add all occuring words to the list. \n",
    "        binrep_words.append(tup[0])\n",
    "\n",
    "binrep_words.remove(\"\")\n",
    "\n",
    "df = pd.DataFrame(columns=binrep_words)\n",
    "\n",
    "# Fill dataframe\n",
    "new_row = []\n",
    "for prod_title in Title_list:\n",
    "    for element in binrep_words:\n",
    "        if element in prod_title:\n",
    "            new_row.append(1)\n",
    "        else:\n",
    "            new_row.append(0)\n",
    "            \n",
    "    df.loc[len(df)]= new_row\n",
    "    new_row = []\n",
    "\n",
    "Binary_Vector_Matrix = df\n",
    "Binary_Vector_Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before obtaining an LSH algorithm, we apply min-hashing. We compress the binary vectors into signature vectors, resulting into a smaller set of elements. Each vector is assigned a signature in such a way that similar products receive the same signature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35.,  33.,  98., ...,  20.,  23.,   2.],\n",
       "       [  9., 117.,  66., ...,  67., 290., 225.],\n",
       "       [ 35.,   9.,  26., ...,  20., 166.,   3.],\n",
       "       ...,\n",
       "       [ 35.,  33., 123., ...,  63., 124.,   3.],\n",
       "       [ 35.,   9.,  26., ...,  67., 259.,   3.],\n",
       "       [132., 109.,  97., ...,  20., 124.,   3.]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minhashing\n",
    "HF = 60 #set hash function\n",
    "\n",
    "datatrans = Binary_Vector_Matrix.transpose()\n",
    "datatrans\n",
    "\n",
    "signaturematrix = np.full((HF, len(datatrans.columns)), np.inf) #create new array\n",
    "\n",
    "for i in range(HF):\n",
    "    datatrans = shuffle(datatrans) #apply permutations     \n",
    "        \n",
    "    for prod in datatrans:\n",
    "        value = list(datatrans[prod]).index(1) #find the first '1' in the row\n",
    "        signaturematrix[i][prod] = value #store corresponding rownumber\n",
    "        \n",
    "sigmat = signaturematrix.T\n",
    "sigmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSH algorithm\n",
    "We will now apply LSH to the signature matrix. We aim to find candidate pairs out of the matrix. Creating the algorithm consists of several steps. We create separate functions in Python for this. <br>\n",
    "\n",
    "First of all, we create the bucketmatrix. For each band $b$, we use a hash function to hash the vector into a certain bucket. LSH should hash two products to the same bucket if they are likely to be similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to create bucketmatrix\n",
    "\n",
    "def LSH(M, b, r):\n",
    "    n, d = M.shape\n",
    "    assert(d==b*r) #continue if statement holds\n",
    "\n",
    "    bucket_matrix = np.full((b, n), 0) #create new array   \n",
    "\n",
    "    k=0\n",
    "    for band in range(b): #loop over bands\n",
    "        signaturelist = [] #create empty list\n",
    "\n",
    "        for product in range(n): #loop over products\n",
    "            partsignature = M[product, k:r+k]\n",
    "            signmatch = list(partsignature % 10)\n",
    "            \n",
    "            if signmatch not in signaturelist: #making buckets\n",
    "                signaturelist.append(signmatch)\n",
    "            else:\n",
    "                None\n",
    "\n",
    "            bucket = signaturelist.index(signmatch)\n",
    "            bucket_matrix[band][product] = bucket    \n",
    "        \n",
    "        k = k + r\n",
    "        \n",
    "    return bucket_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2, ...,  11,   2, 269],\n",
       "       [  0,   1,   2, ...,   2,  34,  34],\n",
       "       [  0,   1,   2, ...,   4,  58,  10],\n",
       "       ...,\n",
       "       [  0,   1,   2, ...,  39,  40,  12],\n",
       "       [  0,   1,   0, ...,  19,  19,   0],\n",
       "       [  0,   1,   2, ..., 109, 408,   6]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 15 #set number of bands\n",
    "r = 4 #set number of rows\n",
    "buckmat = LSH(sigmat, b, r)\n",
    "buckmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two products that are hashed to the same bucket will be considered as a candidate pair. Hence, we now create some code for finding the candidate pairs. We make use of the bucket matrix ('buckmat) obtained from the previous function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining candidate pairs\n",
    "\n",
    "cpairs = set() #initialize set\n",
    "hb = collections.defaultdict(set)\n",
    "\n",
    "for bandnr in range(b): #loop over all bands\n",
    "    band = list(buckmat[bandnr]) \n",
    "    for bucketnr in set(band): #loop over the buckets\n",
    "        for i in range(len(band)):\n",
    "            if band[i]==bucketnr:  \n",
    "                hb[bucketnr].add(i) #add hash bucket if band index equals bucket number\n",
    "            else:\n",
    "                None \n",
    "                \n",
    "    for bucketnr in hb.values():\n",
    "        if len(bucketnr)>1:\n",
    "            for pair in itertools.combinations(bucketnr,2): #find possible combinations\n",
    "                cpairs.add(pair) #label pairs as candidate pair\n",
    "\n",
    "#cpairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the candidate pairs, we consider the problem of considering the pairs under a certain threshold value. We do this to find the right balance between the number of false positives and false negatives. As threshold we set a value of 0.51 (based on the Jaccard threshold of $\\frac{1}{b}^{\\frac{1}{r}}$). Two items are considered a 'real' candidate pair if the computed Jaccard similarity is bigger than the threshold value. The Jaccard similarity is computed for the signatures of the created signature matrix.\n",
    "\n",
    "We first create a function to calculate and return a Jaccard similarity. Then, we create a set of 'real' LSH pairs, satisfying the chosen threshold value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating Jaccard similarity\n",
    "def jacsim(one, two):\n",
    "    s1 = set(one)\n",
    "    s2 = set(two)\n",
    "    \n",
    "    return float(len(s1.intersection(s2))/len(s1.union(s2)))\n",
    "\n",
    "testjaccard = jacsim(sigmat[1], sigmat[2])\n",
    "\n",
    "# Store candidate pairs that meet threshold requirement\n",
    "threshold = 0.51\n",
    "\n",
    "realcpairs = set()\n",
    "for(i,j) in cpairs:\n",
    "    if jacsim(sigmat[i], sigmat[j]) > threshold:\n",
    "        realcpairs.add((i,j))\n",
    "\n",
    "#realcpairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our LSH algorithm is now finished: it returns candidate pairs that we can work with. These potential pairs will now be used to find the official duplicate pairs. This will be considered in the code below. As products can only be classified as duplicate if they come from different stores, we remove the candidate pairs having the same Web shop. \n",
    "\n",
    "For identification of actual duplicates, we measure the Eucledian distance between the binary vectors of the potential pairs. We again have to specify a threshold, in such a way that some but not all pairs will be labeled as actual pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function to calculate Eucledian distance for vectors in matrix\n",
    "\n",
    "def EucDist(vec1, vec2):\n",
    "    a = list(vec1)\n",
    "    b = list(vec2)\n",
    "    \n",
    "    c = [ai - bi for ai, bi in zip(a, b)]\n",
    "    dist = np.linalg.norm(c)\n",
    "    \n",
    "    return dist\n",
    "\n",
    "testEUC = EucDist(Binary_Vector_Matrix.iloc[1], Binary_Vector_Matrix.iloc[6])\n",
    "testEUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating function for similarity measure\n",
    "\n",
    "def preddups(binmat, obs, threshold_euc, realcpairs, include_dist = False):\n",
    "    shop = dataframe[obs]['shop'] #extract shops from dataframe\n",
    "    \n",
    "    # Search within LSH-pairs\n",
    "    pairs = []\n",
    "    \n",
    "    for val in realcpairs: #remove candidate pairs coming from same Web shop\n",
    "        if val[0] == obs:\n",
    "            if dataframe[val[1]]['shop'] != shop: \n",
    "                pairs.append(val[1]) \n",
    "            else:\n",
    "                None\n",
    "        else:\n",
    "            None\n",
    "        \n",
    "    eucpairs = []    \n",
    "    for pair in pairs: \n",
    "        dist = EucDist(binmat.iloc[obs], binmat.iloc[pair])\n",
    "        if dist < threshold_euc:\n",
    "            if include_dist == True:\n",
    "                eucpairs.append((pair, dist))\n",
    "            else:\n",
    "                eucpairs.append(pair)    \n",
    "    \n",
    "    return eucpairs\n",
    "\n",
    "testpreddups = actualduplicates(Binary_Vector_Matrix, 15, 5, realcpairs)\n",
    "#testpreddups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the useful functions, we check our predictions. Next, we are curious to know the total number of predictions, the number of correct predictions and the number of duplicates found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1624/1624 [00:37<00:00, 42.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Checking predictions\n",
    "predictions = pd.DataFrame(columns=['product','predicted_duplicates','true_duplicates']) #create dataframe\n",
    "\n",
    "for product in tqdm(range(len(dataframe))):\n",
    "    true_duplicates = []\n",
    "    predicted_duplicates = preddups(Binary_Vector_Matrix, product, 3.5, realcpairs)\n",
    "    \n",
    "    for item in range(len(dataframe)):\n",
    "        if (dataframe[item]['modelID'] == dataframe[product]['modelID']) & (item!=product):\n",
    "            true_duplicates.append(item)\n",
    "    \n",
    "    predictions = predictions.append({'product':product, 'predicted_duplicates':predicted_duplicates, 'true_duplicates':true_duplicates}, \n",
    "                 ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>predicted_duplicates</th>\n",
       "      <th>true_duplicates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1216, 974, 12, 1107, 1154, 1439, 1314]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[1328, 1085]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[235, 716, 1443, 715, 565, 477, 713, 485, 328,...</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  product                               predicted_duplicates true_duplicates\n",
       "0       0                                                 []              []\n",
       "1       1            [1216, 974, 12, 1107, 1154, 1439, 1314]              []\n",
       "2       2                                                 []              []\n",
       "3       3                                                 []              []\n",
       "4       4                                                 []              []\n",
       "5       5                                       [1328, 1085]              []\n",
       "6       6                                                 []              []\n",
       "7       7                                                 []              []\n",
       "8       8                                                 []              []\n",
       "9       9  [235, 716, 1443, 715, 565, 477, 713, 485, 328,...            [10]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798 5579 178 0.03190535938340204\n"
     ]
    }
   ],
   "source": [
    "# Calculating predictions and duplicates\n",
    "totalpreds = 0\n",
    "correctpreds = 0\n",
    "totaldups = 0\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    for prediction in predictions.iloc[i]['predicted_duplicates']:     \n",
    "        totalpreds+=1\n",
    "        if prediction in predictions.iloc[i]['true_duplicates']:\n",
    "            correctpreds +=1\n",
    "    for duplicate in predictions.iloc[i]['true_duplicates']: \n",
    "        totaldups+=1\n",
    "            \n",
    "print(totaldups, totalpreds, correctpreds, (correctpreds/totalpreds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step for us to take is to evaluate the algorithm. We do this by using a bootstrap function. From the original dataset, we know what the true duplicates are (based on the modelID). Hence, we use this for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating true pairs from dataset\n",
    "TruePair = []\n",
    "\n",
    "for i in range(len(dataframe)):\n",
    "    for j in range(len(dataframe)):\n",
    "        if(dataframe[i]['modelID']==dataframe[j]['modelID']) & (i !=j):\n",
    "            if (j,i) not in TruePair:\n",
    "                TruePair.append((i,j))\n",
    "            else:\n",
    "                None\n",
    "                \n",
    "len(TruePair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function for generating true pairs\n",
    "def GenTruePair(dataframe):\n",
    "    TruePair = []\n",
    "\n",
    "    for i in range(len(dataframe)):\n",
    "        for j in range(len(dataframe)):\n",
    "            if(dataframe[i]['modelID']==dataframe[j]['modelID']) & (i !=j):\n",
    "                if (j,i) not in TruePair:\n",
    "                    TruePair.append((i,j))\n",
    "                else:\n",
    "                    None \n",
    "    return TruePair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining bootstrap function for evaluation\n",
    "\n",
    "randomlist = sample(range(0, 1623), int(1624*0.63))\n",
    "\n",
    "def bootstrap(truepairs, dataframe, binmat, threshold_euc, realcpairs, reps): \n",
    "    dups = set()\n",
    "    for p in truepairs:\n",
    "        dups.add(p[0])\n",
    "        dups.add(p[1])\n",
    "\n",
    "    total_dups = len(dups)\n",
    "\n",
    "    for i in tqdm(range(reps)): #do specified number of bootstrap repetitions\n",
    "\n",
    "        total = range(0,1624) #product range\n",
    "        train = sample(range(0, 1623), int(1624*0.63)) #63% of original data\n",
    "        print(train[0])\n",
    "        test = [x for x in total if x not in randomlist]\n",
    "\n",
    "        train_datalist = []\n",
    "        for num in train:\n",
    "            train_datalist.append(dataframe[num])\n",
    "\n",
    "        test_datalist = []\n",
    "        for num in test:\n",
    "            test_datalist.append(dataframe[num])\n",
    "\n",
    "        train_pairs = GenTruePair(train_datalist)\n",
    "\n",
    "        total_preds = 0 #initialize\n",
    "        correct_preds = 0 #initialize\n",
    "\n",
    "        for product in test: #evaluate predictions\n",
    "            predicted_dups = preddups(Binary_Vector_Matrix, product, threshold_euc, realcpairs)\n",
    "            total_preds = total_preds + len(predicted_dups)\n",
    "\n",
    "            for pd in predicted_dups:\n",
    "                if ((pd, product) in truepairs) | ((product, pd) in truepairs):\n",
    "                    correct_preds = correct_preds + 1\n",
    "        \n",
    "        print(total_dups, total_preds, correct_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "691 8550 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [00:14<00:56, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638\n",
      "691 8550 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:25<00:40, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942\n",
      "691 8550 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:37<00:25, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "691 8550 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:50<00:12, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "691 8550 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:03<00:00, 12.69s/it]\n"
     ]
    }
   ],
   "source": [
    "threshold_euc = 5.0\n",
    "reps = 5\n",
    "\n",
    "bootstrap(TruePair, dataframe, Binary_Vector_Matrix, threshold_euc, realcpairs, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
